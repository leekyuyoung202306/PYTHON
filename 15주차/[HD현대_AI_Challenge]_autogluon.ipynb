{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !unzip '/content/drive/MyDrive/HD현대 AI Challenge/HD현대AI챌린지.zip'"
      ],
      "metadata": {
        "id": "eF-nD_n8iqdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3Cq6t-ihfPu",
        "outputId": "d3fa8aee-b53d-42bb-a712-e0a7c3cc456b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Encoding features: 100%|██████████| 6/6 [00:05<00:00,  1.17it/s]\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "import bisect\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "train = pd.read_csv('train.csv').drop(columns=['SAMPLE_ID'])\n",
        "test = pd.read_csv('test.csv').drop(columns=['SAMPLE_ID'])\n",
        "\n",
        "# datetime 컬럼 처리\n",
        "train['ATA'] = pd.to_datetime(train['ATA'])\n",
        "test['ATA'] = pd.to_datetime(test['ATA'])\n",
        "\n",
        "# datetime을 여러 파생 변수로 변환\n",
        "for df in [train, test]:\n",
        "    df['year'] = df['ATA'].dt.year\n",
        "    df['month'] = df['ATA'].dt.month\n",
        "    df['day'] = df['ATA'].dt.day\n",
        "    df['hour'] = df['ATA'].dt.hour\n",
        "    df['minute'] = df['ATA'].dt.minute\n",
        "    df['weekday'] = df['ATA'].dt.weekday\n",
        "\n",
        "# datetime 컬럼 제거\n",
        "train.drop(columns='ATA', inplace=True)\n",
        "test.drop(columns='ATA', inplace=True)\n",
        "\n",
        "# Categorical 컬럼 인코딩\n",
        "categorical_features = ['ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'ID', 'SHIPMANAGER', 'FLAG']\n",
        "encoders = {}\n",
        "\n",
        "for feature in tqdm(categorical_features, desc=\"Encoding features\"):\n",
        "    le = LabelEncoder()\n",
        "    train[feature] = le.fit_transform(train[feature].astype(str))\n",
        "    le_classes_set = set(le.classes_)\n",
        "    test[feature] = test[feature].map(lambda s: '-1' if s not in le_classes_set else s)\n",
        "    le_classes = le.classes_.tolist()\n",
        "    bisect.insort_left(le_classes, '-1')\n",
        "    le.classes_ = np.array(le_classes)\n",
        "    test[feature] = le.transform(test[feature].astype(str))\n",
        "    encoders[feature] = le\n",
        "\n",
        "# # 결측치 처리  갈룬이 전처리도 담당\n",
        "# train.fillna(train.mean(), inplace=True)\n",
        "# test.fillna(train.mean(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CI_HOUR"
      ],
      "metadata": {
        "id": "Z5FDGz3biI8H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install autogluon"
      ],
      "metadata": {
        "id": "jbIAxhqph8Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor"
      ],
      "metadata": {
        "id": "y73B_Q5_iu3W"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TabularDataset(train)\n",
        "save_path = 'automodel'\n",
        "predictor =  TabularPredictor(\n",
        "    label = 'CI_HOUR',\n",
        "    path=save_path,\n",
        "    eval_metric = 'mean_absolute_error',\n",
        "    problem_type = 'regression'\n",
        ")\n",
        "predictor.fit(\n",
        "    train_data = train_data,\n",
        "    presets = 'best_quality',\n",
        "    time_limit = 60*10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtUUc18qj0qW",
        "outputId": "3046cac9-2072-4700-eca0-cc2734b83f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"automodel\"\n",
            "Presets specified: ['best_quality']\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
            "Beginning AutoGluon training ... Time limit = 600s\n",
            "AutoGluon will save models to \"automodel/\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Wed Aug 30 11:19:59 UTC 2023\n",
            "Disk Space Avail:   81.02 GB / 115.66 GB (70.0%)\n",
            "Train Data Rows:    367441\n",
            "Train Data Columns: 30\n",
            "Label Column: CI_HOUR\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11602.56 MB\n",
            "\tTrain Data (Original)  Memory Usage: 88.19 MB (0.8% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 14 | ['DIST', 'BREADTH', 'DEPTH', 'DRAUGHT', 'LENGTH', ...]\n",
            "\t\t('int', [])   : 16 | ['ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'ID', 'BUILT', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 14 | ['DIST', 'BREADTH', 'DEPTH', 'DRAUGHT', 'LENGTH', ...]\n",
            "\t\t('int', [])   : 16 | ['ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'ID', 'BUILT', ...]\n",
            "\t1.6s = Fit runtime\n",
            "\t30 features in original data used to generate 30 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 88.19 MB (0.8% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 3.48s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 397.58s of the 596.51s of remaining time.\n",
            "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 1019.69s compared to 516.35s of available time.\n",
            "\tTime limit exceeded... Skipping KNeighborsUnif_BAG_L1.\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 393.89s of the 592.82s of remaining time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FJ1HxVUWk3q0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}