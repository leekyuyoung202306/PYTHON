{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ez-1j6_8fvQ5"
      },
      "outputs": [],
      "source": [
        "# 표준 오토인코더\n",
        "# 확장을 해서 변이형 오토인코더"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets\n",
        "(x_train,y_train),(x_test,y_test) = datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LapQfJXjgF7j",
        "outputId": "0f1fe1ad-e66b-4e59-cde9-b698e9439e59"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnmHtf5ch3GN",
        "outputId": "4621715e-8b3f-4f9b-8959-9c367eb78777"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "Sv-hgwghiX5D"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫번째 차원은 가장 바깥쪽 차원을 0개 추가 그래서 변하지 않음\n",
        "# 두번째 차원은 좌,우 각각 2개의 값으로 추가, 좌우 각각2열이 0으로 패딩이 추가\n",
        "# 세번째 차원은 위,아래 각각 2개의 값으로 추가, 좌우 각각2열이 0으로 패딩이 추가\n",
        "temp = np.pad(x_train,((0,0),(2,2),(2,2)),constant_values=0.0)\n",
        "print(temp.shape)\n",
        "np.expand_dims(temp,-1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kWWfMgJiIPP",
        "outputId": "4e2ee9d5-47b9-414d-a713-6b36130e9dad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 32, 32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 32, 32, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 : float32, /255.0\n",
        "# 각 이미지에 패딩을 적용해서 32 x 32 : 신경망 통과시 텐서의 크기를 쉽게 조작할수 있도록\n",
        "def preprocess(imgs):\n",
        "  imgs = imgs.astype('float32') / 255.0\n",
        "  imgs = np.pad(imgs,((0,0),(2,2),(2,2)),constant_values=0.0)\n",
        "  imgs = np.expand_dims(imgs,-1)\n",
        "  return imgs\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)"
      ],
      "metadata": {
        "id": "bRZceEfEhK3K"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더 : 고차원 입력데이터를 저차원 임베딩 벡터로 압축\n",
        "# 디코더 : 임베딩 벡터를 원본 도메인으로 압축 해제(이미지로 되돌린다)\n",
        "# 인코더를 수행하면...특징들을 모은 임베딩(잠재공간).. 임베딩을 샘플링해서 디코더에 넣으면 새로운 이미지생성"
      ],
      "metadata": {
        "id": "xRZsSwAPibOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers,models\n",
        "import tensorflow.keras.backend as k"
      ],
      "metadata": {
        "id": "WNgY3rp3kgVr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k.int_shape(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0PALcgDlnhz",
        "outputId": "d80723fc-d09e-4ba0-c437-72b63b139a50"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 32, 32, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#인코더\n",
        "encorder_input = layers.Input(shape=(32, 32, 1))\n",
        "x = layers.Conv2D(32,(3,3),strides=2,activation='relu',padding='same')(encorder_input)\n",
        "x = layers.Conv2D(64,(3,3),strides=2,activation='relu',padding='same')(x)\n",
        "x = layers.Conv2D(128,(3,3),strides=2,activation='relu',padding='same')(x)\n",
        "shape_before_flatten = k.int_shape(x)[1:]  # 디코더에서 사용\n",
        "x = layers.Flatten()(x)\n",
        "encorder_output = layers.Dense(2)(x)\n",
        "encorder = models.Model(encorder_input,encorder_output)"
      ],
      "metadata": {
        "id": "PD1nRZOykbbV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.prod(shape_before_flatten), shape_before_flatten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATzuOXvkms49",
        "outputId": "9568b1be-2cf8-4fe9-86b2-6583e2c340ba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2048, (4, 4, 128))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코더\n",
        "decorder_input = layers.Input(shape=(2,))\n",
        "x = layers.Dense(np.prod(shape_before_flatten))(decorder_input)\n",
        "x = layers.Reshape(shape_before_flatten)(x)\n",
        "x = layers.Conv2D(128,(3,3),strides=2,activation='relu',padding='same')(x)\n",
        "x = layers.Conv2D(64,(3,3),strides=2,activation='relu',padding='same')(x)\n",
        "x = layers.Conv2D(32,(3,3),strides=2,activation='relu',padding='same')(x)\n",
        "decoder_output = layers.Conv2D(1,(3,3),strides=1,activation='sigmoid',padding='same')(x) # 이미지 그려야..\n",
        "decorder = models.Model(decorder_input,decoder_output)"
      ],
      "metadata": {
        "id": "O7EVsmOlmT9V"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#오토인코더 : 인코더+디코더\n",
        "autoencorder = models.Model(encorder_input, decorder(encorder_output))  # 이미지를 입력으로 받아서 인코더와 디코더를 통과"
      ],
      "metadata": {
        "id": "PdEg2noInz9Y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FHxezDL8oUIn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}