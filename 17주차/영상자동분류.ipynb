{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QFGuyrlvwCko"
      },
      "outputs": [],
      "source": [
        "# 데이터는 CIFAR10 10가지 분류....\n",
        "# 모델을만들어서\n",
        "# 분류하고자한는 이미지가 폴더에 있을때. 해당 폴더로 자동으로 분류(이동)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.applications import ResNet50"
      ],
      "metadata": {
        "id": "8_Kxeht1wniB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
        "# 정규화\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "metadata": {
        "id": "cJTpKIWkxOVo"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape[1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBaTbSlPx75c",
        "outputId": "0dce3d04-ca6c-4fbb-cda5-09b216faf204"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9NfNCLGzMQK",
        "outputId": "d544cd3f-7cf9-4a6d-a3ec-6ffdec3ee822"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       ...,\n",
              "       [9],\n",
              "       [1],\n",
              "       [1]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.framework import tensor\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape = x_train.shape[1:])\n",
        "# 가중치 동결하지 않는 경우 기존 가중치와 함께 학습이 되어서\n",
        "# 훈련데이터가 충분하지 않으면 기존 가중치의 영향에 묻혀서 제대로 반영이 안될수 있음\n",
        "\n",
        "# 기존 모델의 가중치를 동결 해제\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = True\n",
        "\n",
        "# 마지막에 우리 분류기 넣는다.\n",
        "model = keras.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256,activation='relu'),\n",
        "    layers.Dense(10,activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss = tf.keras.losses.sparse_categorical_crossentropy,metrics=['accuracy'])\n",
        "model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuhDDdL5xrDo",
        "outputId": "e01eb7fb-d6ee-4d4b-83fb-392f463832a4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 121s 52ms/step - loss: 1.3722 - accuracy: 0.5368 - val_loss: 1.3279 - val_accuracy: 0.5248\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 80s 51ms/step - loss: 1.1805 - accuracy: 0.5948 - val_loss: 2.3247 - val_accuracy: 0.4771\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 76s 49ms/step - loss: 1.0470 - accuracy: 0.6450 - val_loss: 1.1283 - val_accuracy: 0.6194\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 91s 58ms/step - loss: 0.8935 - accuracy: 0.6996 - val_loss: 1.2287 - val_accuracy: 0.5814\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 77s 49ms/step - loss: 0.9350 - accuracy: 0.6799 - val_loss: 2.3567 - val_accuracy: 0.3897\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 81s 52ms/step - loss: 0.8166 - accuracy: 0.7213 - val_loss: 1.1047 - val_accuracy: 0.6511\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 80s 51ms/step - loss: 0.6745 - accuracy: 0.7720 - val_loss: 0.9539 - val_accuracy: 0.6676\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 82s 52ms/step - loss: 0.6157 - accuracy: 0.7942 - val_loss: 0.7444 - val_accuracy: 0.7524\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 76s 49ms/step - loss: 0.5844 - accuracy: 0.8026 - val_loss: 1.7338 - val_accuracy: 0.5103\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 69s 44ms/step - loss: 0.7133 - accuracy: 0.7631 - val_loss: 1.2969 - val_accuracy: 0.5448\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78d7ab7d0790>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))"
      ],
      "metadata": {
        "id": "E0N1TjMv1GPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('resnet50_cifar10.h5')\n",
        "model = keras.models.load_model('resnet50_cifar10.h5')"
      ],
      "metadata": {
        "id": "5dXjYFAE1HSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/test_images.zip' -d 'test_imgs'"
      ],
      "metadata": {
        "id": "lMvzk0xw1WVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from glob import glob"
      ],
      "metadata": {
        "id": "5yTSUhdz2cLS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_files = glob('./test_imgs/*.jpg')\n",
        "img_files[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t461Lypk2pvm",
        "outputId": "98bc2d0e-cbda-46f3-8b7e-ff662d3fee20"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./test_imgs/12.jpg', './test_imgs/04.jpg', './test_imgs/02.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(img_files[0])\n",
        "x_tests = []\n",
        "x = np.array(img.resize([32,32])) / 255.0\n",
        "x_tests.append(x)\n",
        "x_tests = np.array(x_tests)\n",
        "np.argmax(model.predict(x_tests))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEeOP6jp25Zs",
        "outputId": "bcae5dd0-d925-4e85-a5c6-496376898ad0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classs_names = ['airplane',\n",
        "'automobile'\t\t\t\t\t\t\t,\n",
        "'bird'\t\t\t\t\t\t\t\t\t\t,\n",
        "'cat'\t\t\t\t\t\t\t\t\t\t,\n",
        "'deer'\t\t\t\t\t\t\t\t\t,\n",
        "'dog'\t\t\t\t\t\t\t\t\t\t,\n",
        "'frog'\t\t\t\t\t\t\t\t\t,\n",
        "'horse'\t\t\t\t\t\t\t\t\t,\n",
        "'ship'\t\t\t\t\t\t\t\t\t,\n",
        "'truck']\n",
        "classs_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJSPRhjf4lLI",
        "outputId": "01d4f066-a8ea-42b9-e255-5f66333abcbc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['airplane',\n",
              " 'automobile',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "tests = []\n",
        "origin_images = []\n",
        "for file in img_files:\n",
        "  img = Image.open(file)\n",
        "  origin_images.append(img)\n",
        "  x = np.array(img.resize([32,32])) / 255.0\n",
        "  tests.append(x)\n",
        "tests = np.array(tests)\n",
        "print(tests.shape)\n",
        "preds = model.predict(tests)\n",
        "print(len(preds))\n",
        "pred_index =  [np.argmax(pred) for pred in preds]\n",
        "print(pred_index)\n",
        "for i, idx in enumerate(pred_index):  # i는 예측한 이미지의 순서 idx는 해당 클래스\n",
        "  if not os.path.isdir(classs_names[idx]):\n",
        "    os.mkdir(classs_names[idx])\n",
        "\n",
        "  os.chdir(classs_names[idx])\n",
        "\n",
        "  origin_images[i].save( img_files[i].split('/')[-1] )\n",
        "  os.chdir('../')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a2X1H554xR-",
        "outputId": "c4a5c130-cc6c-494f-d7f7-6b74c6767b1d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 32, 32, 3)\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "12\n",
            "[7, 6, 2, 1, 4, 6, 8, 2, 8, 8, 8, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(origin_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnFdCVbZ-Zb0",
        "outputId": "8f5f395f-e18a-4ee0-f2de-bad6f9329d4e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}